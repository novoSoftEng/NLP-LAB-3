{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9118503-45e6-4b01-b18a-458d827a408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c45201-686f-45fd-84c6-ad4c85ccf8f0",
   "metadata": {},
   "source": [
    "# Part 1: Language Modeling / Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cafe57-96d4-433e-8fd8-f72e97b52a25",
   "metadata": {},
   "source": [
    "### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d097ebaa-29ac-460a-a0e1-08785331709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627eb862-b4a7-4c79-84ab-e0cc4ea7a4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1  1.2  1.3  1.4  1.5  1.6  1.7  2.1  2.2  2.3  2.4  2.5  2.6  2.7\n",
      "  3.1  3.2  3.3  3.4  3.5  3.6  3.7  4.1  4.2  4.3  4.4  4.5  4.6  4.7\n",
      "  5.1  5.2  5.3  5.4  6.1  6.2  6.3  6.4  6.5  6.6  6.7  7.1  7.2  7.3\n",
      "  7.4  7.5  7.6  7.7  8.1  8.2  8.3  8.4  8.5  8.6  8.7  9.1  9.2  9.3\n",
      "  9.4  9.5  9.6  9.7 10.1 10.2 10.3 10.4 10.5 10.6 10.7 11.1 11.2 11.3\n",
      " 11.4 11.5 11.6 11.7 11.8 11.9 12.1 12.2 12.3 12.4 12.5 12.6 12.7 12.8\n",
      " 12.9]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"id\"].unique())\n",
    "print(df[\"correct\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68da059f-8c4f-4989-b594-f625f61ef541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             answer  score  correct\n",
       "0  1.1  High risk problems are address in the prototyp...    3.5      0.0\n",
       "1  1.1  To simulate portions of the desired final prod...    5.0      1.0\n",
       "2  1.1  A prototype program simulates the behaviors of...    4.0      1.0\n",
       "3  1.1  Defined in the Specification phase a prototype...    5.0      1.0\n",
       "4  1.1  It is used to let the users have a first idea ...    3.0      0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff276f7-e25b-4aea-acac-6910a83effb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0333ef52-cce2-4390-9f1e-dd58efb4a005",
   "metadata": {},
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65511a96-c653-4d08-9c44-37e7d611b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/unamed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/unamed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/unamed/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab03923-69c2-4052-86ce-b8f69759fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize necessary components\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e811f9b-1069-4f5d-a64b-f4405233fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Stop words removal\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Stemming\n",
    "    tokens_stemmed = [ps.stem(word) for word in tokens]\n",
    "    \n",
    "    # Lemmatization\n",
    "    tokens_lemmatized = [lemmatizer.lemmatize(word) for word in tokens_stemmed]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return ' '.join(tokens_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da8bb49-220b-4ca9-b851-4870d8d2ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 answer  score  correct\n",
      "0     high risk problem address prototyp program mak...    3.5      0.0\n",
      "1     simul portion desir final product quick easi p...    5.0      1.0\n",
      "2     prototyp program simul behavior portion desir ...    4.0      1.0\n",
      "3     defin specif phase prototyp stimul behavior po...    5.0      1.0\n",
      "4     use let user first idea complet program allow ...    3.0      0.0\n",
      "...                                                 ...    ...      ...\n",
      "2437                                              log n    5.0      1.0\n",
      "2438                                     minu 1 divid 2    1.5      0.0\n",
      "2439                                               2n-1    2.5      0.0\n",
      "2440                      take h step , h height tree .    5.0      1.0\n",
      "2441  depend instal search tree whatev case repeat b...    1.5      0.0\n",
      "\n",
      "[2442 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "df['answer'] = df['answer'].apply(preprocess_text)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1083a3-2d4e-4831-b3a3-46777ea26b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the answer column for Word2Vec\n",
    "df['tokenized_answer'] = df['answer'].apply(nltk.word_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa8ca4a-e80c-448f-bb47-2c5b2ec7e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [high, risk, problem, address, prototyp, progr...\n",
       "1       [simul, portion, desir, final, product, quick,...\n",
       "2       [prototyp, program, simul, behavior, portion, ...\n",
       "3       [defin, specif, phase, prototyp, stimul, behav...\n",
       "4       [use, let, user, first, idea, complet, program...\n",
       "                              ...                        \n",
       "2437                                             [log, n]\n",
       "2438                                  [minu, 1, divid, 2]\n",
       "2439                                               [2n-1]\n",
       "2440               [take, h, step, ,, h, height, tree, .]\n",
       "2441    [depend, instal, search, tree, whatev, case, r...\n",
       "Name: tokenized_answer, Length: 2442, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df1643c9-f31c-4f4b-b0a0-95e2f76572eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec - CBOW\n",
    "cbow_model = Word2Vec(sentences=df['tokenized_answer'], vector_size=100, window=5, min_count=1, sg=0)\n",
    "# Word2Vec - Skip Gram \n",
    "skipgram_model = Word2Vec(sentences=df['tokenized_answer'], vector_size=100, window=5, min_count=1, sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11000d13-d875-49ba-9ad3-b031471f01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(model, tokens):\n",
    "    # Ensure tokens are in the model's vocabulary\n",
    "    valid_tokens = [token for token in tokens if token in model.wv]\n",
    "    if not valid_tokens:\n",
    "        return [0] * model.vector_size\n",
    "    # Compute the average of the word vectors\n",
    "    return sum(model.wv[token] for token in valid_tokens) / len(valid_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ebcaffe-57eb-4e88-9ce9-53d29f79160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW Sentence Embeddings:\n",
      " 0       [0.018987974, 0.22650962, 0.108676255, -0.2046...\n",
      "1       [0.011788357, 0.18661962, 0.09015037, -0.16836...\n",
      "2       [0.017538091, 0.21272016, 0.10427611, -0.19417...\n",
      "3       [0.014323343, 0.19639497, 0.097186245, -0.1761...\n",
      "4       [0.014706535, 0.18933487, 0.092767335, -0.1709...\n",
      "                              ...                        \n",
      "2437    [0.024387639, 0.17015204, 0.052350625, -0.1456...\n",
      "2438    [0.021012291, 0.25003892, 0.10352617, -0.22135...\n",
      "2439    [-0.008946666, 0.0018900299, -0.004067398, 0.0...\n",
      "2440    [0.016542342, 0.24928032, 0.12825942, -0.21960...\n",
      "2441    [0.012801052, 0.19975168, 0.10980461, -0.18189...\n",
      "Name: cbow_embedding, Length: 2442, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to get embeddings\n",
    "df['cbow_embedding'] = df['tokenized_answer'].apply(lambda tokens: get_sentence_embedding(cbow_model, tokens))\n",
    "print(\"CBOW Sentence Embeddings:\\n\", df['cbow_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2407719-1c80-4147-95bd-5946bc59120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip Gram Sentence Embeddings:\n",
      " 0       [0.0053549623, 0.0361633, 0.112275854, 0.01101...\n",
      "1       [-0.013536243, 0.022897307, 0.11400955, 0.0120...\n",
      "2       [0.0056831785, 0.040357243, 0.12781449, -0.005...\n",
      "3       [-0.0006274767, 0.03175342, 0.120221324, 0.010...\n",
      "4       [0.004510333, 0.035062883, 0.117898084, 0.0048...\n",
      "                              ...                        \n",
      "2437    [0.08700921, 0.16013557, -0.034487374, -0.0242...\n",
      "2438    [0.020342002, 0.12897387, 0.007920422, -0.0231...\n",
      "2439    [-0.008946666, 0.0018900299, -0.004067398, 0.0...\n",
      "2440    [0.021881243, 0.0062250155, 0.13907202, 0.0275...\n",
      "2441    [-0.016174663, -0.025009086, 0.14812441, 0.027...\n",
      "Name: sg_embedding, Length: 2442, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['sg_embedding'] = df['tokenized_answer'].apply(lambda tokens: get_sentence_embedding(skipgram_model, tokens))\n",
    "print(\"skip Gram Sentence Embeddings:\\n\", df['sg_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0c968a6-4c63-42a8-943b-0cf7283531df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Representation:\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Feature Names:\n",
      " ['000000' '0the' '0x' ... 'your' 'zero' 'zillion']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(df['answer'])\n",
    "\n",
    "print(\"Bag of Words Representation:\\n\", X_bow.toarray())\n",
    "print(\"Feature Names:\\n\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26e549c7-c752-4a3d-9274-acb7e8b6b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Feature Names:\n",
      " ['000000' '0the' '0x' ... 'your' 'zero' 'zillion']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['answer'])\n",
    "\n",
    "print(\"TF-IDF Representation:\\n\", X_tfidf.toarray())\n",
    "print(\"Feature Names:\\n\", tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf84dee-c3b6-4784-9c57-973b5a49f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape \n",
      " : (2442, 100)\n",
      "y shape \n",
      " : (2442,)\n",
      "SVR Mean Squared Error: 1.7081355269385852\n",
      "SVR Mean Absolute Error: 0.8831747887436259\n",
      "SVR Cross-Validation Mean Squared Error: 1.501548671434419\n",
      "SVR Cross-Validation Mean Absolute Error: 0.8098534144620568\n",
      "\n",
      "Linear Regression Mean Squared Error: 1.1601443355595447\n",
      "Linear Regression Mean Absolute Error: 0.8111186780711899\n",
      "Linear Regression Cross-Validation Mean Squared Error: 1.5186704911120006\n",
      "Linear Regression Cross-Validation Mean Absolute Error: 0.9528925043094615\n",
      "\n",
      "Decision Tree Mean Squared Error: 1.9088484673010309\n",
      "Decision Tree Mean Absolute Error: 0.9663818288051418\n",
      "Decision Tree Cross-Validation Mean Squared Error: 2.2580108964649583\n",
      "Decision Tree Cross-Validation Mean Absolute Error: 1.0633033971850225\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for modeling\n",
    "\n",
    "X = pd.DataFrame(df['cbow_embedding'].tolist())#df.drop(columns=[\"tokenized_answer\",\"sg_embedding\",\"answer\",\"score\"])\n",
    "X.add(df[\"correct\"], axis=1)\n",
    "y = df[\"score\"]\n",
    "print(\"X shape \\n :\", X.shape)\n",
    "print(\"y shape \\n :\", y.shape)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize models\n",
    "svr_model = SVR()\n",
    "linear_model = LinearRegression()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Train and evaluate SVR\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "svr_mse = mean_squared_error(y_test, y_pred_svr)\n",
    "svr_mae = mean_absolute_error(y_test, y_pred_svr)\n",
    "svr_cv_mse = -cross_val_score(svr_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "svr_cv_mae = -cross_val_score(svr_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Train and evaluate Linear Regression\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "linear_mae = mean_absolute_error(y_test, y_pred_linear)\n",
    "linear_cv_mse = -cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "linear_cv_mae = -cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Train and evaluate Decision Tree Regressor\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
    "tree_mae = mean_absolute_error(y_test, y_pred_tree)\n",
    "tree_cv_mse = -cross_val_score(tree_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "tree_cv_mae = -cross_val_score(tree_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Print results\n",
    "print(\"SVR Mean Squared Error:\", svr_mse)\n",
    "print(\"SVR Mean Absolute Error:\", svr_mae)\n",
    "print(\"SVR Cross-Validation Mean Squared Error:\", svr_cv_mse)\n",
    "print(\"SVR Cross-Validation Mean Absolute Error:\", svr_cv_mae)\n",
    "\n",
    "print(\"\\nLinear Regression Mean Squared Error:\", linear_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", linear_mae)\n",
    "print(\"Linear Regression Cross-Validation Mean Squared Error:\", linear_cv_mse)\n",
    "print(\"Linear Regression Cross-Validation Mean Absolute Error:\", linear_cv_mae)\n",
    "\n",
    "print(\"\\nDecision Tree Mean Squared Error:\", tree_mse)\n",
    "print(\"Decision Tree Mean Absolute Error:\", tree_mae)\n",
    "print(\"Decision Tree Cross-Validation Mean Squared Error:\", tree_cv_mse)\n",
    "print(\"Decision Tree Cross-Validation Mean Absolute Error:\", tree_cv_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93cccf74-365f-485e-a46e-871075418bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape \n",
      " : (2442, 100)\n",
      "y shape \n",
      " : (2442,)\n",
      "SVR Mean Squared Error: 1.4885073364180312\n",
      "SVR Mean Absolute Error: 0.8345361108794681\n",
      "SVR Cross-Validation Mean Squared Error: 1.400808093781913\n",
      "SVR Cross-Validation Mean Absolute Error: 0.8198080003435667\n",
      "\n",
      "Linear Regression Mean Squared Error: 1.125377583937165\n",
      "Linear Regression Mean Absolute Error: 0.803104527467518\n",
      "Linear Regression Cross-Validation Mean Squared Error: 1.5284370571591552\n",
      "Linear Regression Cross-Validation Mean Absolute Error: 0.9543217870264348\n",
      "\n",
      "Decision Tree Mean Squared Error: 1.888172290388548\n",
      "Decision Tree Mean Absolute Error: 0.9471370143149284\n",
      "Decision Tree Cross-Validation Mean Squared Error: 2.4156431014086346\n",
      "Decision Tree Cross-Validation Mean Absolute Error: 1.0920047131201964\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(df['sg_embedding'].tolist())#df.drop(columns=[\"tokenized_answer\",\"sg_embedding\",\"answer\",\"score\"])\n",
    "X.add(df[\"correct\"], axis=1)\n",
    "y = df[\"score\"]\n",
    "print(\"X shape \\n :\", X.shape)\n",
    "print(\"y shape \\n :\", y.shape)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialize models\n",
    "svr_model = SVR()\n",
    "linear_model = LinearRegression()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Train and evaluate SVR\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test)\n",
    "svr_mse = mean_squared_error(y_test, y_pred_svr)\n",
    "svr_mae = mean_absolute_error(y_test, y_pred_svr)\n",
    "svr_cv_mse = -cross_val_score(svr_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "svr_cv_mae = -cross_val_score(svr_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Train and evaluate Linear Regression\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "linear_mae = mean_absolute_error(y_test, y_pred_linear)\n",
    "linear_cv_mse = -cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "linear_cv_mae = -cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Train and evaluate Decision Tree Regressor\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, y_pred_tree)\n",
    "tree_mae = mean_absolute_error(y_test, y_pred_tree)\n",
    "tree_cv_mse = -cross_val_score(tree_model, X, y, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "tree_cv_mae = -cross_val_score(tree_model, X, y, cv=5, scoring='neg_mean_absolute_error').mean()\n",
    "\n",
    "# Print results\n",
    "print(\"SVR Mean Squared Error:\", svr_mse)\n",
    "print(\"SVR Mean Absolute Error:\", svr_mae)\n",
    "print(\"SVR Cross-Validation Mean Squared Error:\", svr_cv_mse)\n",
    "print(\"SVR Cross-Validation Mean Absolute Error:\", svr_cv_mae)\n",
    "\n",
    "print(\"\\nLinear Regression Mean Squared Error:\", linear_mse)\n",
    "print(\"Linear Regression Mean Absolute Error:\", linear_mae)\n",
    "print(\"Linear Regression Cross-Validation Mean Squared Error:\", linear_cv_mse)\n",
    "print(\"Linear Regression Cross-Validation Mean Absolute Error:\", linear_cv_mae)\n",
    "\n",
    "print(\"\\nDecision Tree Mean Squared Error:\", tree_mse)\n",
    "print(\"Decision Tree Mean Absolute Error:\", tree_mae)\n",
    "print(\"Decision Tree Cross-Validation Mean Squared Error:\", tree_cv_mse)\n",
    "print(\"Decision Tree Cross-Validation Mean Absolute Error:\", tree_cv_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f6d7a-7511-4542-ab94-930cb7523c38",
   "metadata": {},
   "source": [
    "### Conclusion Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07b439-d23e-4489-beec-baf86b38f952",
   "metadata": {},
   "source": [
    "SVR seems to be the most stable model with consistent performance across both embedding methods.\n",
    "Linear Regression and Decision Tree show higher variance in performance, with Skip Gram embeddings generally yielding better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15481ff-04c8-46ce-bf06-01fb8da43538",
   "metadata": {},
   "source": [
    "# Part 2: Language Modeling / Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80eba41e-2f7e-4e66-a8bd-869c3ae6703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTr = pd.read_csv(\"twitter_training.csv\",names=['id','Entity',\"sentiment\",\"text\"])\n",
    "dTe = pd.read_csv(\"twitter_validation.csv\",names=['id','Entity',\"sentiment\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca698c5-d577-4f7d-881d-716b15f0aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dTr.drop(columns=[\"id\"],inplace=True)\n",
    "dTe.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f253819e-6c99-474c-bdff-ac99a5a57463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):\n",
    "        text = \"\"  # Convert NaN or non-string to an empty string\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the training and validation data\n",
    "dTr['text'] = dTr['text'].apply(preprocess_text)\n",
    "dTe['text'] = dTe['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40eeb469-6ffe-416b-9c3b-91ec53278a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27\n"
     ]
    }
   ],
   "source": [
    "# Combine training and validation data for training Word2Vec\n",
    "combined_data = pd.concat([dTr['text'], dTe['text']])\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=combined_data, vector_size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Get the vocabulary size\n",
    "vocab_size = len(w2v_model.wv.key_to_index)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47157c5d-a8a9-42fe-b694-7b2710779030",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30f4c971-45e0-4c1a-a446-259789768881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(dTr['text']).toarray()\n",
    "\n",
    "# Transform the validation data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(dTe['text']).toarray()\n",
    "\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49770c2e-940e-40e3-b4f0-514c1672b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens, model, vector_size):\n",
    "    if len(tokens) < 1:\n",
    "        return np.zeros(vector_size)\n",
    "    vectorized = [model.wv[word] for word in tokens if word in model.wv.key_to_index]\n",
    "    if len(vectorized) < 1:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(vectorized, axis=0)\n",
    "\n",
    "# Apply the function to get embeddings for training and validation data\n",
    "X_train = np.array([get_average_word2vec(tokens, w2v_model, 100) for tokens in dTr['text']])\n",
    "X_test = np.array([get_average_word2vec(tokens, w2v_model, 100) for tokens in dTe['text']])\n",
    "\n",
    "# Target variable\n",
    "y_train = dTr['sentiment']  # Assuming the sentiment column is the target\n",
    "y_test = dTe['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa4742cd-c084-414d-94c8-2b56dbdd3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "svm_model = SVC()\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8dd115b-ce25-469b-8b1f-6438014db65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.346\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00       172\n",
      "    Negative       0.31      0.66      0.42       266\n",
      "     Neutral       0.43      0.29      0.35       285\n",
      "    Positive       0.37      0.32      0.34       277\n",
      "\n",
      "    accuracy                           0.35      1000\n",
      "   macro avg       0.28      0.32      0.28      1000\n",
      "weighted avg       0.31      0.35      0.30      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Logistic Regression\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_logistic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb8d9895-8690-4953-95ab-2a627aab4d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.874\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.84      0.91      0.87       172\n",
      "    Negative       0.84      0.91      0.87       266\n",
      "     Neutral       0.91      0.85      0.87       285\n",
      "    Positive       0.91      0.84      0.87       277\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.87      0.88      0.87      1000\n",
      "weighted avg       0.88      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4ac857b-df98-493e-a030-28ede53271be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.271\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.00      0.00      0.00       172\n",
      "    Negative       0.27      1.00      0.42       266\n",
      "     Neutral       0.00      0.00      0.00       285\n",
      "    Positive       1.00      0.02      0.04       277\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.32      0.25      0.11      1000\n",
      "weighted avg       0.35      0.27      0.12      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the word vectors\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "nb_model = MultinomialNB()\n",
    "# Train and evaluate Decision Tree\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634ddb2-2e75-44e6-ab2d-006de232b4db",
   "metadata": {},
   "source": [
    "### Conclusion Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0ba88-ccf7-4a49-ae56-a2d4ba322985",
   "metadata": {},
   "source": [
    "Based on the performance metrics, the Decision Tree model significantly outperformed both the Logistic Regression and Naive Bayes models in terms of accuracy and f1-score across all classes. The Decision Tree achieved an accuracy of 86.6% and consistently high precision, recall, and f1-scores for all sentiment categories. In contrast, Logistic Regression and Naive Bayes struggled particularly with the \"Irrelevant\" and \"Neutral\" classes, showing poor precision and recall. \n",
    "\n",
    "Therefore, for this sentiment analysis task using Skip-Gram embeddings, the Decision Tree model is the most effective, providing the best balance between precision and recall across all sentiment categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d9909-02da-437a-a11c-f191d87c10d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
